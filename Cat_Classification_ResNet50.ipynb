{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad577279-5a69-4dc2-86ba-bad435278905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # For visualization\n",
    "\n",
    "# import necessary library\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637144b8-5fe9-4d5d-ac1f-dbf52218288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will import train , validation and test data\n",
    "training_data_path = '/Users/kittipot/Desktop/Cat_project_dataset/train'\n",
    "validation_data_path = '/Users/kittipot/Desktop/Cat_project_dataset/validate'\n",
    "test_data_path = '/Users/kittipot/Desktop/Cat_project_dataset/test'\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    directory=training_data_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    directory=validation_data_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,  # For validation & test set we will not shuffle\n",
    "    seed=123,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    directory=test_data_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,  # For validation & test set we will not shuffle\n",
    "    seed=123,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60f2d9-43b4-4b4f-ae9a-b5a84e9d0cb7",
   "metadata": {},
   "source": [
    "การที่ validation_set และ test_set ไม่ต้องทำการ shuffle (สุ่มลำดับข้อมูล) มีเหตุผลสำคัญที่เกี่ยวข้องกับการรักษาความถูกต้องของการทดสอบและการประเมินโมเดล:\n",
    "\n",
    "1. Consistency in Evaluation:\n",
    "Test Set: ชุดข้อมูลทดสอบ (test set) ใช้สำหรับการประเมินประสิทธิภาพของโมเดลหลังจากการฝึก (training) แล้ว โดยที่ข้อมูลในชุดทดสอบจะต้องเป็นตัวแทนที่ตรงของปัญหาที่โมเดลจะเจอในโลกจริง ซึ่งการ shuffle ข้อมูลใน test set อาจทำให้ผลลัพธ์ที่ได้ไม่สามารถสะท้อนถึงประสิทธิภาพของโมเดลได้อย่างถูกต้อง เพราะผลลัพธ์ที่โมเดลได้อาจขึ้นอยู่กับลำดับของข้อมูลที่มันได้รับ (เช่น การทำนายตามลำดับเวลาในปัญหาที่มีการจัดเรียงลำดับข้อมูล)\n",
    "Validation Set: ชุดข้อมูล validation ใช้สำหรับการเลือกโมเดลที่ดีที่สุดในระหว่างการฝึก ซึ่งจะช่วยในการปรับพารามิเตอร์ต่างๆ เช่น learning rate, architecture ของโมเดล เป็นต้น ดังนั้นชุดข้อมูล validation ควรจะเป็นข้อมูลที่มีลำดับชัดเจนเพื่อให้สามารถประเมินและปรับแต่งโมเดลได้อย่างสม่ำเสมอ\n",
    "\n",
    "2. Data Integrity:\n",
    "การ shuffle ชุดข้อมูลอาจทำให้โมเดลเห็นข้อมูลที่อาจไม่สัมพันธ์กันหรือมีการกระจายข้อมูลที่ไม่เหมาะสม ตัวอย่างเช่น ถ้ามีการจัดลำดับข้อมูลตามประเภทหรือป้ายกำกับ การ shuffle อาจทำให้การประเมินผลบนข้อมูลเหล่านั้นไม่ถูกต้อง\n",
    "นอกจากนี้ สำหรับการใช้งาน cross-validation หรือการแบ่งชุดข้อมูลหลายๆ รอบ (k-fold cross-validation) ข้อมูลอาจจะถูกแบ่งเป็นชุดต่างๆ แต่การ shuffle จะช่วยให้แน่ใจว่าโมเดลได้เห็นข้อมูลในลักษณะที่มีความหลากหลาย\n",
    "\n",
    "3. สรุป:\n",
    "Test set: ไม่มีการ shuffle เพื่อให้การประเมินโมเดลสามารถทำได้อย่างถูกต้องและมีความสอดคล้องกับข้อมูลที่โมเดลจะพบในอนาคต\n",
    "Validation set: ไม่มีการ shuffle เพื่อให้โมเดลสามารถถูกปรับแต่งได้อย่างมีประสิทธิภาพ โดยยังคงความสมบูรณ์ของข้อมูล"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867273f-1613-4c4c-84e4-a4b7a76a5e16",
   "metadata": {},
   "source": [
    "1. Image Size (image_size):\n",
    "ResNet50 ถูกออกแบบมาให้รับข้อมูลที่มีขนาด 224x224 pixels เป็นขนาดเริ่มต้นของภาพ ซึ่งจะดีที่สุดสำหรับการฝึกหรือทำนายด้วยโมเดลนี้\n",
    "2. Batch Size:\n",
    "Batch Size คือจำนวนภาพที่ถูกป้อนให้โมเดลในแต่ละรอบ (iteration) ของการฝึก จำนวนที่เหมาะสมคือ 32/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061dcb6-43af-456b-bbb3-8bfa720f377e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next We will use pretrainmodel: Resnet50\n",
    "\n",
    "# Load model ResNet50 not included top layer (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add a new layer to continue training from the model that has already been trained\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Reduce data dimensions\n",
    "\n",
    "# Fully Connected Layer 1 with LeakyReLU\n",
    "x = Dense(512)(x)  # Not inspect activation\n",
    "x = LeakyReLU(negative_slope=0.01)(x)  # Use LeakyReLU\n",
    "x = Dropout(0.5)(x)  # Regularization\n",
    "\n",
    "# Fully Connected Layer 2 with LeakyReLU\n",
    "x = Dense(256)(x)  # Not inspect activation\n",
    "x = LeakyReLU(negative_slope=0.01)(x)  # Use LeakyReLU\n",
    "x = Dropout(0.5)(x)  # Regularization\n",
    "\n",
    "# Output Layer\n",
    "predictions = Dense(12, activation='softmax')(x)  # Output Layer (12 classes)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Freeze ResNet50's layers so they are not used in training (train only the new layers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summarize model stucture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075af53-c866-4045-9d75-729b38e340f1",
   "metadata": {},
   "source": [
    "base_model.output หมายถึงการใช้ output (ผลลัพธ์) ที่ได้จากการประมวลผลของโมเดล ResNet50 ซึ่งในกรณีนี้เป็นโมเดลที่โหลดมาพร้อมกับพารามิเตอร์ weights='imagenet' (ใช้พารามิเตอร์ที่ฝึกมาจาก ImageNet).\n",
    "หลังจากการโหลดโมเดล ResNet50 แล้ว, base_model.output จะเป็น output ของ layer สุดท้ายที่ไม่รวม top layer (เนื่องจาก include_top=False). ซึ่งจะได้เป็นฟีเจอร์ที่มีความละเอียดสูงจากการประมวลผลของ ResNet50 แต่ยังไม่ได้มีการแปลงออกเป็นคลาสสุดท้าย (classification layer).\n",
    "ค่านี้จะถูกใช้เป็น input ของ layer ถัดไปในโมเดลของเรา เพื่อฝึกฝนต่อจากโมเดลที่ได้ฝึกไว้แล้ว (transfer learning).\n",
    "\n",
    "ประโยชน์ของ GlobalAveragePooling2D:\n",
    "ลดมิติข้อมูลจาก 3D (เช่น ขนาดของ feature map เป็น (height, width, channels)) ให้เหลือแค่ 1D โดยการคำนวณค่าเฉลี่ยในแต่ละช่อง.\n",
    "มันช่วยลดจำนวนพารามิเตอร์ในโมเดลและลดความเสี่ยงจากการ overfitting เนื่องจากไม่ต้องใช้ dense layer ที่มีพารามิเตอร์มากเกินไป.\n",
    "ผลลัพธ์ที่ได้คือ vector ที่มีความยาวเท่ากับจำนวน channels ของ feature map (เช่น ถ้า feature map มี 2048 channels ก็จะได้ vector ขนาด 2048).\n",
    "\n",
    "เหตุผลที่ต้อง Freeze Layer ของ ResNet50\n",
    "การดึงคุณลักษณะ (Feature Extraction):\n",
    "โมเดลที่ฝึกมาแล้ว เช่น ResNet50 มักจะฝึกด้วยชุดข้อมูลขนาดใหญ่ (เช่น ImageNet) และได้เรียนรู้การดึงคุณลักษณะที่มีประโยชน์จากภาพ (เช่น ขอบ, เนื้อผ้า, รูปร่าง ฯลฯ) ซึ่งคุณลักษณะเหล่านี้มักจะสามารถนำมาใช้ใหม่ได้ในงานอื่น ๆ โดยเฉพาะเมื่องานใหม่นั้นเกี่ยวข้องกับข้อมูลที่คล้ายกับข้อมูลที่โมเดลได้ฝึกไว้\n",
    "การ freeze layer จะช่วยให้คุณลักษณะที่เรียนรู้จากโมเดล ResNet50 ไม่ถูกปรับเปลี่ยน และโมเดลจะไม่ลืมความสามารถในการดึงคุณลักษณะจากภาพ\n",
    "ฝึกเฉพาะ Layer ใหม่ (Fine-tuning):\n",
    "layer ใหม่ที่เพิ่มเข้าไป (เช่น Dense layer หรือ layer ที่ปรับแต่งอื่น ๆ) คือส่วนที่เราต้องการให้โมเดลเรียนรู้สำหรับงานเฉพาะ ในการ freeze layer ที่ฝึกมาแล้ว, เราจะมั่นใจได้ว่าแค่ layer ใหม่จะถูกปรับให้เข้ากับงานใหม่ที่กำหนด\n",
    "หลังจากฝึก layer ใหม่เสร็จแล้ว เราสามารถ unfreeze (ปลดการ freeze) บางส่วนของ ResNet50 เพื่อ fine-tune และฝึกเพิ่มเติมในบาง layer ได้ (ถ้าจำเป็น) แต่โดยปกติแล้วการ freeze layer ส่วนใหญ่จะช่วยได้ดีสำหรับหลาย ๆ งาน"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1dbddb-a129-4949-83e6-a5d9d880e4dd",
   "metadata": {},
   "source": [
    "เมื่อเราโหลด ResNet50 ด้วยพารามิเตอร์ include_top=False, หมายความว่าเรากำลังดึงโมเดล ResNet50 โดยไม่รวม fully connected layers หรือ top layers ที่มักจะใช้สำหรับการจำแนกประเภท (classification) ที่โมเดลจะใช้ในการทำนายผลลัพธ์สุดท้ายตามจำนวนคลาส (เช่น, 1000 คลาสใน ImageNet)\n",
    "\n",
    "เหตุผลที่ไม่รวม top layers:\n",
    "การปรับใช้โมเดล (Transfer Learning):\n",
    "การใช้ include_top=False ช่วยให้คุณสามารถใช้โมเดล ResNet50 ที่ถูกฝึกบน ImageNet มาแล้ว (โดยใช้ weights ที่ได้จาก ImageNet) เพื่อเรียนรู้คุณสมบัติทั่วไปของภาพ เช่น การตรวจจับรูปร่าง พื้นผิว และลวดลาย\n",
    "Top layers ของโมเดล ResNet50 ได้รับการฝึกให้ใช้สำหรับการจำแนกภาพตาม 1000 คลาสใน ImageNet เท่านั้น แต่หากเรามีชุดข้อมูลที่ต้องการจำแนกภาพที่มีคลาสแตกต่างออกไป (เช่น 10 หรือ 100 คลาส), เราต้องสร้าง fully connected layers ใหม่ที่เหมาะสมกับจำนวนคลาสในปัญหาของเรา\n",
    "\n",
    "การเรียนรู้เชิงลึกที่มีประสิทธิภาพ (Fine-Tuning):\n",
    "เมื่อไม่รวม top layers, เราสามารถ fine-tune (ฝึกฝน) โมเดลได้ตามต้องการ โดยการปรับแต่ง layer ที่อยู่ด้านบนสุดเพื่อให้มันเหมาะสมกับชุดข้อมูลของเรา\n",
    "บางครั้งอาจจะต้อง \"freeze\" (ล็อก) layers ที่อยู่ลึกในโมเดล (เช่น layers ที่อยู่ใน ResNet50) และฝึกเพียง layer ใหม่ที่เพิ่มเข้าไปเท่านั้น เพื่อให้โมเดลสามารถทำงานได้ดีขึ้นกับข้อมูลใหม่\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac43ab19-97ed-4f09-aa01-9697c52373a9",
   "metadata": {},
   "source": [
    "ข้อดีของ LeakyReLU เมื่อเทียบกับ ReLU\n",
    "แก้ปัญหา \"Dead Neurons\"\n",
    "ReLU อาจทำให้เกิดปัญหา \"Dead Neurons\" เมื่อค่าที่ส่งผ่านเข้า activation มีค่าน้อยกว่าศูนย์ จะทำให้ผลลัพธ์เป็นศูนย์เสมอในเลเยอร์นั้น และไม่มีการอัปเดตน้ำหนักของ neuron นั้นเลย\n",
    "LeakyReLU ช่วยแก้ปัญหานี้ด้วยการให้ค่าลบเล็กน้อยแทนการเป็นศูนย์\n",
    "เหมาะสำหรับข้อมูลที่มีความหลากหลาย\n",
    "หากข้อมูลภาพของเรามีความหลากหลายสูง (เช่น การจัดแสงหรือมุมมองที่แตกต่างกันมาก) LeakyReLU อาจช่วยให้โมเดลเรียนรู้ได้ดีกว่าเพราะไม่มี neuron ตาย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7e54d-2ea3-4fc8-9e04-63c386381d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start train model on training_dataset & validation model on validation_dataset\n",
    "\n",
    "history = model.fit(train_dataset, validation_data=validation_dataset, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78317e-a59d-493b-a008-377bcf076ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model that already train\n",
    "model.save('/Users/kittipot/Desktop/Machine Learning Files/Cat_Classification_Resnet50.keras')  # Save as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0959e-6319-4f28-825f-7eb5e9975937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model('/Users/kittipot/Desktop/Machine Learning Files/Cat_Classification_Resnet50.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e049ed-3dd0-441a-b9bb-3a15eb19bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model loss/validation loss to use next time\n",
    "# Save history\n",
    "history_path = '/Users/kittipot/Desktop/Machine Learning Files/Cat_loss.pkl'\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a2054-3e6b-4566-a71c-d73284c4afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model loss/validation loss\n",
    "# Load history data\n",
    "history_path = '/Users/kittipot/Desktop/Machine Learning Files/Cat_loss.pkl'\n",
    "with open(history_path, 'rb') as f:\n",
    "    loaded_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73676ca9-fc89-4f5b-bd2c-7d766f1e4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training loss VS Validation loss During Train Process\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\"\"\"loss = loaded_history['loss'] # in case you load files history, use this line code\n",
    "val_loss = loaded_history['val_loss']\"\"\"\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744365f-c8a8-4270-812a-76c489cf95ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Do the prediction and check performance metrics\n",
    "validation_predict = model.predict(validation_dataset)\n",
    "test_predict = model.predict(test_dataset)\n",
    "validation_predict.shape, test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb8d8e-8534-4b40-be6b-b41cc0f62cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect result\n",
    "print(np.round(validation_predict, 2))\n",
    "print(np.round(test_predict, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3f387-c09a-49e5-ab5b-f308585b7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will visualize model prediction\n",
    "\n",
    "def predict_and_display_topk_keras(model, dataset, k, idx_to_class):\n",
    "    \"\"\"\n",
    "    Perform prediction on a dataset and display the top-k predictions\n",
    "    along with the image and true labels for Keras/TensorFlow models.\n",
    "    \n",
    "    Args:\n",
    "    - model: Trained Keras/TensorFlow model for prediction.\n",
    "    - dataset: Dataset to predict on (e.g., validation_dataset or test_dataset).\n",
    "    - k: Number of top predictions to display.\n",
    "    - idx_to_class: Mapping of class indices to class names.\n",
    "    \n",
    "    Returns:\n",
    "    - None (Displays images and predictions)\n",
    "    \"\"\"\n",
    "    for images, labels in dataset:  # Loop through batches\n",
    "        # Perform prediction\n",
    "        predictions = model.predict(images)  # Get predictions (logits or probabilities)\n",
    "        \n",
    "        for i in range(len(images)):  # Loop through each image in the batch\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            \n",
    "            # Display the image\n",
    "            img = images[i].numpy() # Convert images data from tensor to numpy array\n",
    "            img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(f\"True Label: {idx_to_class[labels[i].numpy()]}\")\n",
    "            plt.show()\n",
    "\n",
    "            # Get top-k predictions\n",
    "            probs = predictions[i]\n",
    "            top_indices = np.argsort(probs)[::-1][:k]  # Indices of top-k probabilities\n",
    "            top_probs = probs[top_indices]\n",
    "\n",
    "            # Print top-k predictions\n",
    "            print(f\"Top {k} Predictions:\")\n",
    "            for j in range(k):\n",
    "                class_name = idx_to_class[top_indices[j]]\n",
    "                probability = top_probs[j] * 100\n",
    "                print(f\"- {class_name}: {probability:.2f}%\")\n",
    "            \n",
    "            print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180721ed-a3fb-4e79-b62c-6c072e0f7e0c",
   "metadata": {},
   "source": [
    "1.PyTorch/TensorFlow ใช้ tensor ในการจัดการข้อมูลขณะฝึกโมเดล ซึ่งการแปลงเป็น NumPy array จะทำให้สามารถใช้ฟังก์ชันการแสดงผลของ Matplotlib ได้\n",
    "\n",
    "2.การทำ (img - img.min()) / (img.max() - img.min()) จะนำค่าพิกเซลของภาพมาปรับให้เหมาะสมกับการแสดงผลใน Matplotlib เพราะการแสดงผลภาพใน Matplotlib ต้องการให้ค่าพิกเซลอยู่ในช่วง [0, 1] สำหรับการแสดงผลที่ถูกต้อง\n",
    "เหตุผล: ข้อมูลพิกเซลในภาพบางครั้งอาจจะไม่ได้อยู่ในช่วง [0, 1] เช่น อาจจะเป็น [0, 255] หรือช่วงอื่น ๆ การ Normalize ทำให้ภาพมีค่าพิกเซลในช่วงที่เหมาะสมสำหรับการแสดงผล\n",
    "\n",
    "3.idx_to_class[labels[i].numpy()] คือการแปลงค่า label (ที่เป็นเลข) ให้เป็นชื่อของ class ที่เกี่ยวข้อง (ตัวแปร idx_to_class เป็น dictionary ที่แปลง label เป็นชื่อ class เช่น 0 -> \"cat\", 1 -> \"dog\" ฯลฯ)\n",
    "เหตุผล: การตั้งชื่อภาพ (title) จะช่วยให้ผู้ดูภาพสามารถรู้ได้ว่า \"ภาพนี้แท้จริงแล้วเป็นอะไร\" โดยที่ label ที่แท้จริงจะถูกแสดง\n",
    "\n",
    "4.predictions[i] คือผลลัพธ์ของการทำนายสำหรับตัวอย่างที่ i ซึ่งจะเป็นอาร์เรย์ของค่าความน่าจะเป็น (probabilities) สำหรับแต่ละคลาส\n",
    "np.argsort(probs) จะส่งคืนดัชนีของค่าในอาร์เรย์ probs ที่ถูกเรียงจากค่าน้อยไปหามาก\n",
    "[::-1] ใช้เพื่อกลับลำดับให้เป็นจากค่ามากไปหาน้อย\n",
    "[:k] จะเลือกแค่ k ค่าที่มีความน่าจะเป็นสูงสุด\n",
    "เหตุผล: เพื่อหาดัชนีของ k ค่าความน่าจะเป็นที่สูงที่สุด (หรือคลาสที่มีความน่าจะเป็นสูงสุด) ซึ่งจะเป็นการค้นหาคำทำนายที่มีโอกาสมากที่สุด\n",
    "probs[top_indices] จะดึงค่าความน่าจะเป็นที่มีดัชนีตรงกับ top_indices ที่เราคัดเลือกออกมา\n",
    "\n",
    "5.for j in range(k):\n",
    "คำอธิบาย: วนลูปเพื่อทำงานกับแต่ละอันดับของ top-k predictions\n",
    "k คือจำนวนของอันดับที่ต้องการแสดง (เช่น k = 3 หมายถึงแสดง top-3 predictions)\n",
    "range(k) สร้างลูปจำนวน k ครั้ง สำหรับแต่ละค่าใน top_indices และ top_probs\n",
    "เหตุผล: ใช้ลูปเพื่อแสดงผลของ top-k predictions ทีละตัว\n",
    "\n",
    "6.class_name = idx_to_class[top_indices[j]]\n",
    "คำอธิบาย: ใช้ดัชนีจาก top_indices[j] เพื่อดึงชื่อของคลาสจาก idx_to_class\n",
    "idx_to_class เป็น dictionary ที่เชื่อมโยงจากดัชนี (index) ไปยังชื่อของคลาส\n",
    "top_indices[j] คือดัชนีของคลาสที่มีความน่าจะเป็นสูงที่สุดในลำดับที่ j\n",
    "class_name จึงจะได้ชื่อของคลาสที่ตรงกับดัชนีนี้\n",
    "เหตุผล: เพื่อแสดงชื่อของคลาสที่มีความน่าจะเป็นสูงสุดในแต่ละอันดับ\n",
    "\n",
    "7.print(f\"- {class_name}: {probability:.2f}%\")\n",
    "คำอธิบาย: การพิมพ์ชื่อของคลาสและค่าความน่าจะเป็นในรูปเปอร์เซ็นต์ (สองตำแหน่งหลังจุดทศนิยม)\n",
    "{class_name} จะถูกแทนที่ด้วยชื่อของคลาส\n",
    "{probability:.2f} แสดงค่าเปอร์เซ็นต์ที่มีสองตำแหน่งหลังจุดทศนิยม\n",
    "\n",
    "8.print(\"-\" * 50)\n",
    "คำอธิบาย: พิมพ์เครื่องหมายขีด \"-\" 50 ตัวเพื่อใช้เป็นเส้นคั่น (separator) เพื่อแยกผลลัพธ์ของแต่ละตัวอย่างการทำนายออกจากกัน\n",
    "เหตุผล: เส้นคั่นช่วยให้การแสดงผลหลายตัวอย่างดูเป็นระเบียบและเข้าใจง่าย โดยช่วยแยกกลุ่มของข้อมูลแต่ละชุด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c263e50-0970-426b-baeb-35aa1579b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from class indices to class names\n",
    "idx_to_class = {\n",
    "    0: \"Abyssinian\", 1: \"Bengal\", 2: \"Birman\", 3: \"Bombay\", 4: \"British_Shorthair\",\n",
    "    5: \"Egyptian_Mau\", 6: \"Maine_Coon\", 7: \"Persian\", 8: \"Ragdoll\",\n",
    "    9: \"Russian_Blue\", 10: \"Siamese\", 11: \"Sphynx\"\n",
    "}\n",
    "\n",
    "# Predict and display top-3 predictions for validation dataset\n",
    "predict_and_display_topk_keras(model, validation_dataset, k=3, idx_to_class=idx_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcde84-a213-43e0-bce9-4c1ab1b7c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and display top-3 predictions for test dataset\n",
    "predict_and_display_topk_keras(model, test_dataset, k=3, idx_to_class=idx_to_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
